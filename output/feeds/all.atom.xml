<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Matthew Kudija</title><link href="http://matthewkudija.com/blog/" rel="alternate"></link><link href="http://matthewkudija.com/blog/feeds/all.atom.xml" rel="self"></link><id>http://matthewkudija.com/blog/</id><updated>2018-03-15T06:00:00-04:00</updated><entry><title>Code Block Highlighting</title><link href="http://matthewkudija.com/blog/blog/2018/03/15/code-block/" rel="alternate"></link><published>2018-03-15T06:00:00-04:00</published><updated>2018-03-15T06:00:00-04:00</updated><author><name>Matthew Kudija</name></author><id>tag:matthewkudija.com,2018-03-15:blog/blog/2018/03/15/code-block/</id><summary type="html">

&lt;p&gt;I test code block highlighting...&lt;/p&gt;
</summary><category term="python"></category><category term="makefile"></category><category term="make"></category></entry><entry><title>Automation Using Makefiles</title><link href="http://matthewkudija.com/blog/blog/2018/03/15/makefiles/" rel="alternate"></link><published>2018-03-15T06:00:00-04:00</published><updated>2018-03-15T06:00:00-04:00</updated><author><name>Matthew Kudija</name></author><id>tag:matthewkudija.com,2018-03-15:blog/blog/2018/03/15/makefiles/</id><summary type="html">

&lt;p&gt;Makefiles provide an easy way to group multiple terminal commands into a single command using &lt;code&gt;make &amp;lt;command&amp;gt;&lt;/code&gt;. This gives a brief overview with just enough enformation to write your first Makefile.&lt;/p&gt;
</summary><category term="python"></category><category term="makefile"></category><category term="make"></category></entry><entry><title>Setting Up A Pelican Blog on GitHub Pages</title><link href="http://matthewkudija.com/blog/blog/2018/03/06/pelican-blog/" rel="alternate"></link><published>2018-03-06T06:00:00-05:00</published><updated>2018-03-06T06:00:00-05:00</updated><author><name>Matthew Kudija</name></author><id>tag:matthewkudija.com,2018-03-06:blog/blog/2018/03/06/pelican-blog/</id><summary type="html">

&lt;p&gt;A typical scatter plot allows you to compare the impact of one independent variable (&lt;em&gt;x-axis&lt;/em&gt;) on one dependent variable (&lt;em&gt;y-axis&lt;/em&gt;). There are several ways to show the impact of two or more independent variables, but carpet plots offer some distinct advantages.&lt;/p&gt;
</summary><category term="pelican"></category></entry><entry><title>Carpet Plots</title><link href="http://matthewkudija.com/blog/blog/2018/02/14/carpet-plots/" rel="alternate"></link><published>2018-02-14T06:00:00-05:00</published><updated>2018-02-14T06:00:00-05:00</updated><author><name>Matthew Kudija</name></author><id>tag:matthewkudija.com,2018-02-14:blog/blog/2018/02/14/carpet-plots/</id><summary type="html">

&lt;h2&gt;Why Carpet Plots?&lt;/h2&gt;
&lt;p&gt;A typical scatter plot allows you to compare the impact of one independent variable (&lt;em&gt;x-axis&lt;/em&gt;) on one dependent variable (&lt;em&gt;y-axis&lt;/em&gt;). There are several ways to show the impact of two or more independent variables, but carpet plots offer some distinct advantages.&lt;/p&gt;
</summary><category term="pandas"></category><category term="plotly"></category></entry><entry><title>3D Interactive Rubik's Cube in Python</title><link href="http://matthewkudija.com/blog/blog/2012/11/26/3d-interactive-rubiks-cube-in-python/" rel="alternate"></link><published>2012-11-26T22:00:00-05:00</published><updated>2012-11-26T22:00:00-05:00</updated><author><name>Matthew Kudija</name></author><id>tag:matthewkudija.com,2012-11-26:blog/blog/2012/11/26/3d-interactive-rubiks-cube-in-python/</id><summary type="html">

&lt;p&gt;Over the weekend, I built a interactive 3D Rubik's cube simulator in python
using only &lt;a href="http://matplotlib.org"&gt;matplotlib&lt;/a&gt; for all the graphics and
interaction.  Check out the demonstration here:&lt;/p&gt;
&lt;p&gt;&lt;span class="videobox"&gt;
            &lt;video width="680" height="400" preload="none" controls poster="/downloads/videos/MagicCube_frame.jpg"&gt;&lt;source src='/downloads/videos/MagicCube.mp4' type='video/mp4; codecs="avc1.42E01E, mp4a.40.2"'&gt;&lt;/video&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;You can browse the source code at the MagicCube github repository:
&lt;a href="http://github.com/davidwhogg/MagicCube"&gt;http://github.com/davidwhogg/MagicCube&lt;/a&gt;.&lt;/p&gt;
</summary><category term="matplotlib"></category></entry><entry><title>Why Python is the Last Language You'll Have To Learn</title><link href="http://matthewkudija.com/blog/blog/2012/09/20/why-python-is-the-last/" rel="alternate"></link><published>2012-09-20T20:50:00-04:00</published><updated>2012-09-20T20:50:00-04:00</updated><author><name>Matthew Kudija</name></author><id>tag:matthewkudija.com,2012-09-20:blog/blog/2012/09/20/why-python-is-the-last/</id><summary type="html">

&lt;p&gt;This week, for part of a textbook I'm helping to write,
I spent some time reading and researching the history of Python as
a scientific computing tool.  I had heard bits and pieces of this in the past,
but it was fascinating to put it all together and learn about how all the
individual contributions that have made Python what it is today.
All of this got me thinking: for most of us, Python was a replacement for
something: IDL, MatLab, Java, Mathematica, Perl... you name it.
But what will replace Python?
Ten years down the road, what language will people be espousing in
blogs with awkwardly-alliterated titles?  As I thought it through, I
became more and more convinced that, at least in the scientific computing
world, Python is here to stay.&lt;/p&gt;
</summary><category term="opinion"></category><category term="python"></category></entry><entry><title>Dynamic Programming in Python: Bayesian Blocks</title><link href="http://matthewkudija.com/blog/blog/2012/09/12/dynamic-programming-in-python/" rel="alternate"></link><published>2012-09-12T19:02:00-04:00</published><updated>2012-09-12T19:02:00-04:00</updated><author><name>Matthew Kudija</name></author><id>tag:matthewkudija.com,2012-09-12:blog/blog/2012/09/12/dynamic-programming-in-python/</id><summary type="html">

&lt;p&gt;Of all the programming styles I have learned,
&lt;a href="http://en.wikipedia.org/wiki/Dynamic_programming"&gt;dynamic programming&lt;/a&gt;
is perhaps the most beautiful.  It can take problems that, at first glance,
look ugly and intractable, and solve the problem with clean, concise code.
Where a simplistic algorithm might accomplish something by brute force,
dynamic programming steps back, breaks the task into a smaller set of
sequential parts, and then proceeds in the most efficient way possible.&lt;/p&gt;
&lt;h3&gt;Bayesian Blocks&lt;/h3&gt;
&lt;p&gt;I'll go through an example here where the ideas of dynamic programming
are vital to some very cool data analysis resuts.
This post draws heavily from a recent
&lt;a href="http://adsabs.harvard.edu/abs/2012arXiv1207.5578S"&gt;paper&lt;/a&gt; by Jeff Scargle
and collaborators (this is the Scargle of &lt;em&gt;Lomb-Scargle Periodogram&lt;/em&gt;
fame), as well as some conversations I had with Jeff at
&lt;a href="http://www.astro.caltech.edu/ai12/"&gt;Astroinformatics 2012&lt;/a&gt;.
The paper discusses
a framework called &lt;em&gt;Bayesian Blocks&lt;/em&gt;, which is essentially a method of
creating histograms with bin sizes that adapt to the data (there's a bit
more to it than that: here we'll focus on histograms for simplicity).&lt;/p&gt;
</summary><category term="tutorial"></category></entry><entry><title>Numba vs Cython</title><link href="http://matthewkudija.com/blog/blog/2012/08/24/numba-vs-cython/" rel="alternate"></link><published>2012-08-24T10:41:00-04:00</published><updated>2012-08-24T10:41:00-04:00</updated><author><name>Matthew Kudija</name></author><id>tag:matthewkudija.com,2012-08-24:blog/blog/2012/08/24/numba-vs-cython/</id><summary type="html">

&lt;p&gt;&lt;em&gt;For a more up-to-date comparison of Numba and Cython, see the&lt;/em&gt;
&lt;a href="http://jakevdp.github.io/blog/2013/06/15/numba-vs-cython-take-2/"&gt;&lt;em&gt;newer post&lt;/em&gt;&lt;/a&gt;
&lt;em&gt;on this subject.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Often I'll tell people that I use python for computational analysis, and they
look at me inquisitively.  "Isn't python pretty slow?"  They have a point.
Python is an interpreted language, and as such cannot natively perform
many operations as quickly as a compiled language such as C or Fortran.
There is also the issue of the oft-misunderstood and much-maligned
&lt;a href="http://wiki.python.org/moin/GlobalInterpreterLock"&gt;GIL&lt;/a&gt;,
which calls into question python's ability to allow true parallel computing.&lt;/p&gt;
&lt;p&gt;Many solutions have been proposed: &lt;a href="http://pypy.org/"&gt;PyPy&lt;/a&gt; is a much faster
version of the core python language; 
&lt;a href="http://code.google.com/p/numexpr/"&gt;numexpr&lt;/a&gt; provides optimized performance
on certain classes of operations from within python;
&lt;a href="http://www.scipy.org/Weave/"&gt;weave&lt;/a&gt; allows inline inclusion of compiled
C/C++ code;
&lt;a href="http://www.cython.org/"&gt;cython&lt;/a&gt; provides extra markup that allows python
and/or python-like code to be compiled into C for fast operations.  But
a naysayer might point out: many of these "python" solutions in practice
are not really python at all, but clever hacks into Fortran or C.&lt;/p&gt;
</summary><category term="numba"></category><category term="cython"></category><category term="benchmarks"></category></entry><entry><title>Memoryview Benchmarks 2</title><link href="http://matthewkudija.com/blog/blog/2012/08/16/memoryview-benchmarks-2/" rel="alternate"></link><published>2012-08-16T14:19:00-04:00</published><updated>2012-08-16T14:19:00-04:00</updated><author><name>Matthew Kudija</name></author><id>tag:matthewkudija.com,2012-08-16:blog/blog/2012/08/16/memoryview-benchmarks-2/</id><summary type="html">

&lt;p&gt;In the &lt;a href="/blog/2012/08/08/memoryview-benchmarks/"&gt;previous post&lt;/a&gt;, I explored
how cython typed memoryviews can be used to speed up repeated array
operations.  It became clear that typed memoryviews are superior to
the ndarray syntax for slicing, and as fast as raw pointers for single
element access.  In the comments, Mathieu brought up an interesting
question: is the ndarray syntax as good as typed memoryviews if you're
not doing slicing?&lt;/p&gt;
&lt;p&gt;The answer turns out to be yes, &lt;em&gt;unless&lt;/em&gt; the compiler tries to inline your
function.&lt;/p&gt;
</summary><category term="numpy"></category><category term="cython"></category><category term="benchmarks"></category><category term="memoryviews"></category></entry><entry><title>Memoryview Benchmarks</title><link href="http://matthewkudija.com/blog/blog/2012/08/08/memoryview-benchmarks/" rel="alternate"></link><published>2012-08-08T18:50:00-04:00</published><updated>2012-08-08T18:50:00-04:00</updated><author><name>Matthew Kudija</name></author><id>tag:matthewkudija.com,2012-08-08:blog/blog/2012/08/08/memoryview-benchmarks/</id><summary type="html">

&lt;p&gt;There was recently a &lt;a href="https://groups.google.com/forum/?fromgroups#!topic/cython-users/8uuxjB_wbBQ[1-25]" title="cython-users archive"&gt;thread&lt;/a&gt;
on cython-users which caught my eye.  It has to do with 
&lt;a href="http://docs.cython.org/src/userguide/memoryviews.html"&gt;memoryviews&lt;/a&gt;, a new
way of working with memory buffers in cython.&lt;/p&gt;
&lt;p&gt;I've been thinking recently about how to do fast
and flexible memory buffer access in cython.  I contributed the
&lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.BallTree.html"&gt;BallTree&lt;/a&gt;
implementation for nearest neighbors searching in
&lt;a href="http://www.scikit-learn.org"&gt;scikit-learn&lt;/a&gt;, and have been actively thinking
about how to make it faster and more flexible, including adding the ability
to specify distance metrics other than euclidean and minkowski.&lt;/p&gt;
&lt;p&gt;In order to accomplish this, I'd like to have a set of distance metric
functions which take two vectors and compute a distance.  There would
be many functions with similar call signatures which could then be
plugged into a code that would iterate over a set of vectors and
compute the appropriate distances.&lt;/p&gt;
</summary><category term="benchmarks"></category><category term="numpy"></category><category term="cython"></category></entry></feed>